{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we know if our code is working correctly? It is not when the code runs and returns some value: as seen above, there may be times where it makes sense to stop the code even when it is correct, as it is being used incorrectly. We need to test the code to check that it works.\n",
    "\n",
    "*Unit testing* is the idea of writing many small tests that check if simple cases are behaving correctly. Rather than trying to *prove* that the code is correct in all cases (which could be very hard), we check that it is correct in a number of tightly controlled cases (which should be more straightforward). If we later find a problem with the code, we add a test to cover that case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Teaching note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing isn't always the easiest thing to motivate in a mathematical context, as even [the best discussions](https://www.devmynd.com/blog/five-factor-testing/) focus on CS applications or on complex codes. One approach is to talk about *generality*. A function may be designed to work for integers. Later we may decide that the same concept makes sense for real, or complex, numbers. So we want to extend our function to work for the more complex case. Testing allows us to easily check that, when extending our function, we didn't break it in the earlier cases where it worked.\n",
    "\n",
    "We are intending to use unit tests to *automatically mark* student submissions of weekly work. Knowing how this works in outline is going to be needed to interpret the errors the students see and ask questions about.\n",
    "\n",
    "At least to start, we are *not* intending to use these tests on coursework submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write a simple function that divides two numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divide(x, y):\n",
    "    \"\"\"\n",
    "    Divide two numbers\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    x : float\n",
    "        Numerator\n",
    "    y : float\n",
    "        Denominator\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    x / y : float\n",
    "    \"\"\"\n",
    "    return x / y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we can play with this in the console.\n",
    "\n",
    "We want to check that it does the \"right thing\". How much do we need to check?\n",
    "\n",
    "Check integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "print(divide(4,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check obvious fractions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(divide(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does $a^7 / a = a^6$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5309450437774568 3.5309450437774568\n"
     ]
    }
   ],
   "source": [
    "a = 1.234\n",
    "print(divide(a**7, a), a**6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if you divide by zero? (What should happen?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-da0caa7f6bf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-255c1de61e50>\u001b[0m in \u001b[0;36mdivide\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "print(divide(1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if you divide by a really large number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(divide(1, 1e1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these tests has their uses and may show different potential problems. What counts as \"correct\" depends on how you want your code to handle certain situations.\n",
    "\n",
    "If are function didn't do what we wanted on one of these tests then we'd have to alter it and test again. This can be error prone, so it's better to write functions. We want these functions to complain loudly if something is wrong, but be quiet if all is well. To do this we can use the `assert` statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_integer_division():\n",
    "    assert(divide(4, 2) == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_integer_division()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that nothing happened, as we wanted. However, we can't do that exact test in the case of general real numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_real_division1():\n",
    "    assert(divide(1, 3) == 0.33333333333333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-eb75d319d2de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_real_division1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-a9b2929027ed>\u001b[0m in \u001b[0;36mtest_real_division1\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_real_division1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.33333333333333\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_real_division1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we\n",
    "\n",
    "1. want a way of testing that works with real numbers, i.e., checks that the result is \"close\";\n",
    "2. gives us a better error message so we know what is wrong!\n",
    "\n",
    "We will use functions from `numpy` for this, introduced purely by example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_equal, assert_allclose\n",
    "\n",
    "def test_integer_division():\n",
    "    assert_equal(divide(4, 2), 2, \n",
    "                 err_msg=\"Dividing 4 by 2: answer should be 2\")\n",
    "    \n",
    "def test_real_division1():\n",
    "    assert_allclose(divide(1, 3), 0.33333333333333, \n",
    "                 err_msg=\"Dividing 1 by 3: answer should be 1/3\")\n",
    "\n",
    "def test_power_division():\n",
    "    a = 1.234\n",
    "    assert_allclose(divide(a**7, a), a**6, \n",
    "                 err_msg=\"Dividing a^7 by a: answer should be a^6\")\n",
    "\n",
    "def test_large_division():\n",
    "    assert_equal(divide(1, 1e1000), 0,\n",
    "                 err_msg=\"Dividing by a large enough number returns zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_integer_division()\n",
    "test_real_division1()\n",
    "test_power_division()\n",
    "test_large_division()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did not allow us to check that the division by zero was handled correctly. For that we'll need `pytest`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "def test_zero_division():\n",
    "    with pytest.raises(ZeroDivisionError, \n",
    "                       message=\"Dividing by zero should give a ZeroDivisionError\"):\n",
    "        divide(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_zero_division()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the difference in the syntax between the two ways of testing, which are annoying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `py.test`\n",
    "\n",
    "We now have a set of tests - a *testsuite*, as it is sometimes called - encoded in functions, with meaningful names, which give useful error messages if the test fails. Every time the code is changed, we want to re-run all the tests to ensure that our change has not broken the code. This can be tedious. A better way would be to run a single command that runs all tests. `pytest` is that command.\n",
    "\n",
    "The easiest way to use it is to put all tests in the same file as the function being tested. So, create a file `test_divide.py` containing all the functions above:\n",
    "\n",
    "```python\n",
    "from numpy.testing import assert_equal, assert_allclose\n",
    "import pytest\n",
    "\n",
    "def divide(x, y):\n",
    "    \"\"\"\n",
    "    Divide two numbers\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    x : float\n",
    "        Numerator\n",
    "    y : float\n",
    "        Denominator\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    x / y : float\n",
    "    \"\"\"\n",
    "    return x / y\n",
    "    \n",
    "def test_integer_division():\n",
    "    assert_equal(divide(4, 2), 2, \n",
    "                 err_msg=\"Dividing 4 by 2: answer should be 2\")\n",
    "    \n",
    "def test_real_division1():\n",
    "    assert_allclose(divide(1, 3), 0.33333333333333, \n",
    "                 err_msg=\"Dividing 1 by 3: answer should be 1/3\")\n",
    "\n",
    "def test_power_division():\n",
    "    a = 1.234\n",
    "    assert_allclose(divide(a**7, a), a**6, \n",
    "                 err_msg=\"Dividing a^7 by a: answer should be a^6\")\n",
    "\n",
    "def test_large_division():\n",
    "    assert_equal(divide(1, 1e1000), 0,\n",
    "                 err_msg=\"Dividing by a large enough number returns zero\")\n",
    "                 \n",
    "def test_zero_division():\n",
    "    with pytest.raises(ZeroDivisionError, \n",
    "                       message=\"Dividing by zero should give a ZeroDivisionError\"):\n",
    "        divide(1, 0)\n",
    "        \n",
    "# The following command will run when the file is executed:\n",
    "\n",
    "pytest.main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then execute the file by running it in the Spyder editor. This will define all the functions and the last line will run the tests. You should see output like\n",
    "\n",
    "```\n",
    "===================================== test session starts ======================================\n",
    "platform darwin -- Python 3.6.1, pytest-3.1.1, py-1.4.33, pluggy-0.4.0\n",
    "rootdir: /Users/ih3/Documents/github/orcomp-training, inifile:\n",
    "collected 5 items \n",
    "\n",
    "test_divide.py .....\n",
    "\n",
    "=================================== 5 passed in 0.05 seconds ===================================\n",
    "```\n",
    "\n",
    "Each dot corresponds to a passing test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try modifying the `divide` function so that it will fail in some cases but not others. For example, make it so that the function returns the integer division, rather than the real division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divide(x, y):\n",
    "    \"\"\"\n",
    "    Divide two numbers\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    x : float\n",
    "        Numerator\n",
    "    y : float\n",
    "        Denominator\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    x / y : float\n",
    "    \"\"\"\n",
    "    return x // y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should make the some of the tests fail. Rather than re-running them all individually, we can re-execute the file in Spyder, which uses `pytest` to rerun *all* the tests. You should see something like\n",
    "\n",
    "```\n",
    "===================================== test session starts ======================================\n",
    "platform darwin -- Python 3.6.1, pytest-3.1.1, py-1.4.33, pluggy-0.4.0\n",
    "rootdir: /Users/ih3/Documents/github/orcomp-training, inifile:\n",
    "collected 5 items\n",
    "\n",
    "test_divide.py .FF..\n",
    "\n",
    "=========================================== FAILURES ===========================================\n",
    "_____________________________________ test_real_division1 ______________________________________\n",
    "\n",
    "    def test_real_division1():\n",
    "        assert_allclose(divide(1, 3), 0.33333333333333,\n",
    ">                    err_msg=\"Dividing 1 by 3: answer should be 1/3\")\n",
    "E       AssertionError: \n",
    "E       Not equal to tolerance rtol=1e-07, atol=0\n",
    "E       Dividing 1 by 3: answer should be 1/3\n",
    "E       (mismatch 100.0%)\n",
    "E        x: array(0)\n",
    "E        y: array(0.33333333333333)\n",
    "\n",
    "test_divide.py:29: AssertionError\n",
    "_____________________________________ test_power_division ______________________________________\n",
    "\n",
    "    def test_power_division():\n",
    "        a = 1.234\n",
    "        assert_allclose(divide(a**7, a), a**6,\n",
    ">                    err_msg=\"Dividing a^7 by a: answer should be a^6\")\n",
    "E       AssertionError: \n",
    "E       Not equal to tolerance rtol=1e-07, atol=0\n",
    "E       Dividing a^7 by a: answer should be a^6\n",
    "E       (mismatch 100.0%)\n",
    "E        x: array(3.0)\n",
    "E        y: array(3.5309450437774568)\n",
    "\n",
    "test_divide.py:34: AssertionError\n",
    "============================== 2 failed, 3 passed in 0.60 seconds ==============================\n",
    "```\n",
    "\n",
    "It tells us explicitly\n",
    "\n",
    "* how many tests passed or failed;\n",
    "* which tests failed;\n",
    "* what result was expected and what was actually calculated.\n",
    "\n",
    "Make sure you can see what are the key parts of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify your `divide` function so that all tests except the zero division check pass (for example, make the function do something wrong when the divisor is larger than $10$). Check that you can explain the results."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nbconvert": {
   "title": "Exceptions and testing"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
